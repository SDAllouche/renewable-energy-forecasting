{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21106629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pandas import read_csv\n",
    "import missingno as msno\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error \n",
    "from math import sqrt\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f54d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "df=pd.read_excel(\"./Dataset/solar.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89254e22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87bdb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all nan values\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2562c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb37152",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='Production',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b050f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(16, 16))\n",
    "sns.heatmap(df.corr(), annot=True, square=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d12505",
   "metadata": {},
   "outputs": [],
   "source": [
    "1#evaluation metrics\n",
    "def forecast_accuracy(forecast, actual):\n",
    "    forecast = np.array(forecast)\n",
    "    actual = np.array(actual)\n",
    "    mape = np.mean(np.abs(forecast - actual)/np.abs(actual)) # MAPE\n",
    "    if (type(mape) != int or type(mape) != float):\n",
    "        mape='Zero Devision'\n",
    "    mae = np.mean(np.abs(forecast - actual))    # MAE\n",
    "    rmse = np.mean((forecast - actual)**2)**.5# RMSE\n",
    "    if (max(actual)==min(actual)):\n",
    "        nrmse='Zero Devision'\n",
    "    else:\n",
    "        nrmse=rmse/(max(actual)-min(actual))\n",
    "    corr = np.corrcoef(forecast, actual)[0,1]   # corr\n",
    "    mins = np.amin(np.hstack([forecast[:,None], \n",
    "                              actual[:,None]]), axis=1)\n",
    "    maxs = np.amax(np.hstack([forecast[:,None], \n",
    "                              actual[:,None]]), axis=1)\n",
    "    minmax = 1 - np.mean(mins/maxs)             # minmax\n",
    "    if (type(minmax) != int or type(minmax) != float):\n",
    "        minmax='Zero Devision'\n",
    "    return({'mape':mape,'nrmse':nrmse, 'mae': mae, \n",
    "            'rmse':rmse, 'corr':corr, 'minmax':minmax})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc939eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X_Y(ts: np.array, lag=1, n_ahead=1, target_index=0) -> tuple:\n",
    "    \"\"\"\n",
    "    A method to create X and Y matrix from a time series array for the training of \n",
    "    deep learning models \n",
    "    \"\"\"\n",
    "    # Extracting the number of features that are passed from the array \n",
    "    n_features = ts.shape[1]\n",
    "    \n",
    "    # Creating placeholder lists\n",
    "    X, Y = [], []\n",
    "\n",
    "    if len(ts) - lag <= 0:\n",
    "        X.append(ts)\n",
    "    else:\n",
    "        for i in range(len(ts) - lag - n_ahead):\n",
    "            Y.append(ts[(i + lag):(i + lag + n_ahead), target_index])\n",
    "            X.append(ts[i:(i + lag)])\n",
    "\n",
    "    X, Y = np.array(X), np.array(Y)\n",
    "\n",
    "    # Reshaping the X array to an LSTM input shape \n",
    "    X = np.reshape(X, (X.shape[0], lag, n_features))\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43c00df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of lags to use for models\n",
    "lag = 24\n",
    "# Steps in future to forecast\n",
    "n_ahead = 24\n",
    "# ratio of observations for training from total series\n",
    "train_share = 0.8\n",
    "# training epochs\n",
    "epochs = 50\n",
    "# Batch size , which is the number of samples of lags\n",
    "batch_size = 512\n",
    "# Learning rate\n",
    "lr = 0.001\n",
    "# The features for the modeling \n",
    "features_final = ['Production','ensoleillement','t2m','Panel','u10ff']\n",
    "\n",
    "ts = df[features_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a86dd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling data between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(ts)\n",
    "ts_scaled = scaler.transform(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5b5229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the X and Y for training, the formula is set up to assume the target Y is the left most column = target_index=0\n",
    "X, Y = create_X_Y(ts_scaled, lag=lag, n_ahead=n_ahead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f9703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting into train and test sets \n",
    "Xtrain, Ytrain = X[0:int(X.shape[0] * train_share)], Y[0:int(X.shape[0] * train_share)]\n",
    "Xtest, Ytest = X[int(X.shape[0] * train_share):], Y[int(X.shape[0] * train_share):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950855dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.layers import Dense,RepeatVector, LSTM, Dropout\n",
    "from tensorflow.keras.layers import Flatten, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import Bidirectional, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cc22a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping\n",
    "early_stop = EarlyStopping(monitor = \"loss\", mode = \"min\", patience = 7)\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=256, kernel_size=2, activation='relu', input_shape=(24,5)))\n",
    "model.add(Conv1D(filters=128, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(RepeatVector(30))\n",
    "model.add(LSTM(units=100, return_sequences=True, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=100, return_sequences=True, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=100, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(units=100, return_sequences=True, activation='relu'))\n",
    "model.add(Bidirectional(LSTM(128, activation='relu')))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(24))\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1e34e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(Xtrain,Ytrain,epochs=50, verbose=1, callbacks = [early_stop] )\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4d2ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./cnn-lstm-1.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c6a764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict based on test data\n",
    "yhat = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d81dab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "date=df['date_ech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2ba57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the predictions date range\n",
    "dt=pd.DataFrame(date)\n",
    "days = dt.values[-len(yhat):-len(yhat) + n_ahead]\n",
    "days_df = pd.DataFrame(days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db33b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare resulting series for inverse scaling transformation\n",
    "#pay attention we will select only the first prediction we have made, therefore [0] used to select this window (we have generated multiple prediction sequences of 144 steps ahead, starting from each interval step in the test dataset)\n",
    "pred_n_ahead = pd.DataFrame(yhat[0])\n",
    "actual_n_ahead = pd.DataFrame(Ytest[0])\n",
    "\n",
    "#repeat the column series 2 times, to make shape compatible for scale inversion\n",
    "pr_p = pd.concat([pred_n_ahead]*5, axis=1)\n",
    "ac_p = pd.concat([actual_n_ahead]*5, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c8ae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inverse scale tranform the series back to kiloWatts of power\n",
    "pr_p = pd.DataFrame(scaler.inverse_transform(pr_p))\n",
    "ac_p = pd.DataFrame(scaler.inverse_transform(ac_p))\n",
    "\n",
    "#rename columns\n",
    "pr_p = pr_p.rename(columns={0:'PredPower'})\n",
    "ac_p = ac_p.rename(columns={0:'ActualPower'})\n",
    "\n",
    "#concatenate together into one dataframe and set index\n",
    "df_final = pd.concat([days_df, pr_p['PredPower'], ac_p['ActualPower']], axis=1).set_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a30c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[['PredPower','ActualPower']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a7922e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot n_steps ahead for predicted and actual data\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(df_final.index, df_final.ActualPower, color='C0', marker='o', label='Actual Power')\n",
    "plt.plot(df_final.index, df_final.PredPower, color='C1', marker='o', label='Predicted Power', alpha=0.6)\n",
    "plt.title('Predicted vs Actual Power')\n",
    "plt.gcf().axes[0].yaxis.get_major_formatter().set_scientific(False)\n",
    "plt.legend()\n",
    "plt.savefig('forecast_example.png')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a551d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_accuracy(df_final['PredPower'], df_final['ActualPower'], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8b1b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c960ead5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
